{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# Load the model and processor\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "API_KEY = \"pcsk_V1N5k_2MEH2y1B7ZwGjYKbHXw5twJCGpiyPZ4eEg6GmESWrGVmApeBp6q4gxgNNLYHd9P\"\n",
    "\n",
    "client = Pinecone(\n",
    "    api_key=API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"products.json\" , \"r\") as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "\n",
    "data = data[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_index(\"products\")\n",
    "client.create_index(\"products\" , dimension=512 , metric = \"cosine\" , spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) )\n",
    "\n",
    "index = client.Index(\"products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in index.list():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch\n",
    "vectors = []\n",
    "id = 1\n",
    "i = 1\n",
    "for d in data:\n",
    "    images = d[\"images\"]\n",
    "    for image in images:\n",
    "        res = requests.get(image)\n",
    "        image_ = Image.open(BytesIO(res.content))\n",
    "\n",
    "        inputs = processor(images=image_, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            image_embeddings = list(model.get_image_features(**inputs))\n",
    "        \n",
    "        category_name = d.get(\"category_name\" , \"\")\n",
    "        category_id = str(d.get(\"category_id\" , \"\"))\n",
    "        shop_id = str(d.get(\"shop_id\" , \"\"))\n",
    "        shop_name = d.get(\"shop_name\" , \"\")\n",
    "        link = d.get(\"link\" , \"\")\n",
    "        status = d.get(\"status\" , \"\")\n",
    "        region = d.get(\"region\" , \"\")\n",
    "        images = d.get(\"images\" , \"\")\n",
    "        \n",
    "        vectors.append({\n",
    "                \"values\" : image_embeddings[0],\n",
    "                \"id\" : str(id),\n",
    "                \"metadata\" : {\n",
    "                    \"name\" : d[\"name\"],\n",
    "                    \"pid\" : str(d[\"id\"]),\n",
    "                    \"category_name\" :category_name or \"\" ,\n",
    "                    \"category_id\" : category_id or \"\",\n",
    "                    \"shop_id\":  shop_id or \"\",\n",
    "                    \"shop_name\":  shop_name or \"\",\n",
    "                    \"link\":  link or \"\",\n",
    "                    \"status\":  status or \"\",\n",
    "                    \"region\" : region or \"\",\n",
    "                    \"images\" : images or []\n",
    "                }\n",
    "            })\n",
    "        id +=1\n",
    "        break\n",
    "    print(i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 40}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_relevant_vector(text_description, top_k=10, namespace=None , filters = {}):\n",
    "      # Process the text input to get embeddings\n",
    "      inputs = processor(text=[text_description], return_tensors=\"pt\", padding=True)\n",
    "      with torch.no_grad():\n",
    "           text_embedding = model.get_text_features(**inputs)\n",
    "      text_embedding = text_embedding.squeeze().tolist() \n",
    "      \n",
    "      response = index.query(\n",
    "           namespace=namespace,\n",
    "           vector=text_embedding,\n",
    "           top_k=top_k,\n",
    "           include_values=True,\n",
    "           include_metadata=True,\n",
    "           filter={\"status\" : \"IN_STOCK\"}\n",
    "           )\n",
    " \n",
    "      return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.271046281\n",
      "0.252119809\n",
      "0.243664354\n",
      "0.235029012\n",
      "0.216721714\n",
      "0.216632858\n",
      "0.2144133\n",
      "0.212330014\n",
      "0.211035833\n",
      "0.210574493\n",
      "{'2058607', '2089195', '2089165', '2089194', '2089192', '2089198', '2089197', '2089171', '2089199', '2089193'}\n"
     ]
    }
   ],
   "source": [
    "result = fetch_relevant_vector(\"zebra\")\n",
    "\n",
    "matches = result[\"matches\"]\n",
    "# print(ma)\n",
    "aaa = []\n",
    "for m in matches:\n",
    "    aaa.append(m[\"metadata\"][\"pid\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
